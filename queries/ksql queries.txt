docker compose up -d

docker-compose exec kafka kafka-topics --create --topic test --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

docker-compose exec kafka kafka-topics --describe --topic test --bootstrap-server localhost:9092

docker compose exec broker kafka-console-consumer --bootstrap-server localhost:9092 --topic test --from-beginning --max-messages 30





docker exec -it ksqldb-server ksql http://localhost:8088

SET 'auto.offset.reset' = 'earliest';


CREATE STREAM my_stream ( 
	my_key BIGINT KEY,
	user_id VARCHAR, 
	game_id INT, 
	created_timestamp varchar, 
	real_amount_bet double, 
	real_amount_win double
) with (
	KAFKA_TOPIC='staging_bets', 
	KEY_FORMAT='PROTOBUF', 
	VALUE_FORMAT='JSON', 
	timestamp='created_timestamp', 
	timestamp_format='dd/MM/yyyy HH:mm'
);


CREATE TABLE aggregated_table WITH (
	kafka_topic='my_table', 
	value_format='json'
) AS
select 	timestamptostring(rowtime, 'dd/MM/yyyy') as date,
		game_id, 
		user_id,
		sum(real_amount_bet) as total_bet_amount,
		sum(real_amount_win) as total_win_amount
from my_stream 
window tumbling (size 60 SECONDS)
group by timestamptostring(rowtime, 'dd/MM/yyyy'), game_id, user_id
HAVING 
emit changes 
limit 5;

select * from my_table emit changes limit 5;

;With Numbered as (
    select *,
    ROW_NUMBER() OVER (PARTITION BY [Date, User],CAST(DT as date) ORDER BY Value desc) as rn
    from @t
)
select * from Numbered
where rn=1